# -*- coding: utf-8 -*-
"""ASR_FINAL_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eEuV3d8QwbBW3aTRC-nKrwxIezQM8GdR
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp "kaggle (24).json" ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list -s coswara

!kaggle datasets download -d sarabhian/coswara-dataset-heavy-cough

!unzip coswara-dataset-heavy-cough.zip -d coswara

import os

for root, dirs, files in os.walk('coswara', topdown=True):
    for name in files:
        print(os.path.join(root, name))

import pandas as pd
import glob

# Path to all metadata CSV files
csv_files = glob.glob("coswara/csvs/*.csv")

# Read and combine them
label_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)

# Save as labels.csv
label_df.to_csv("labels.csv", index=False)

print("Labels.csv created â€” total rows:", len(label_df))
label_df.head()

import pandas as pd
import glob

# Collect every metadata CSV inside coswara/csvs/
csv_files = glob.glob("coswara/csvs/*.csv")

# Combine all metadata CSVs into a single dataframe
label_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)

print("Total metadata rows:", len(label_df))
label_df.head()

# Cell 0: Install deps
!pip install --upgrade pip
!pip install kaggle librosa soundfile numpy pandas scikit-learn matplotlib xgboost shap joblib tqdm praat-parselmouth --quiet

# If you run into parselmouth issues, you can remove it; it's optional for jitter/shimmer.
print("Installed packages (may require runtime restart if new).")

# Cell 1: upload kaggle.json (Colab)
from google.colab import files
import os, shutil

print("If you already have /root/.kaggle/kaggle.json, skip uploading.")
uploaded = files.upload()
if uploaded:
    name = list(uploaded.keys())[0]
    os.makedirs('/root/.kaggle', exist_ok=True)
    shutil.move(name, '/root/.kaggle/kaggle.json')
    os.chmod('/root/.kaggle/kaggle.json', 0o600)
    print("kaggle.json installed.")
else:
    print("No file uploaded.")

# Cell 2: download Kaggle dataset (optional if already downloaded)
!kaggle datasets download -d sarabhian/coswara-dataset-heavy-cough -p /content --unzip
!ls -lah /content/coswara || true

# Cell 3: combine metadata CSVs to create labels dataframe
import glob, pandas as pd, os

csv_files = sorted(glob.glob("coswara/csvs/*.csv"))
print("Found", len(csv_files), "metadata CSVs.")
label_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)
print("Combined metadata rows:", len(label_df))
label_df.columns

# Cell 4: inspect and create binary label
print("Unique covid_status values:")
print(sorted(label_df['covid_status'].dropna().unique()))

positive_classes = ['positive_mild', 'positive_asymp', 'positive_moderate']
label_df['binary_label'] = label_df['covid_status'].astype(str).apply(lambda x: 1 if x in positive_classes else 0)

# Keep only id and binary_label for merging
label_df_small = label_df[['id','binary_label']].copy()
label_df_small.shape

# Cell 5: load feature CSV & extract id
feat_path = '/content/coswara/train.csv'   # change if your features file is elsewhere
import pandas as pd
df_feat = pd.read_csv(feat_path)
print("Features shape:", df_feat.shape)
df_feat['id'] = df_feat['filename'].astype(str).apply(lambda x: x.split('/')[-2] if isinstance(x, str) and '/' in x else '')
df_feat[['filename','id']].head(6)

# Cell 6: merge on id
merged = df_feat.merge(label_df_small, on='id', how='inner')
print("Merged shape:", merged.shape)
print("Label distribution after merge:")
print(merged['binary_label'].value_counts(dropna=False))

# Check for missing audio or unmatched IDs (quick diagnostics)
num_feat_ids = df_feat['id'].nunique()
num_label_ids = label_df_small['id'].nunique()
print("Unique feature IDs:", num_feat_ids, " Unique label IDs:", num_label_ids)

# Cell 7: prepare X, y
drop_cols = ['filename','id','binary_label']   # drop any other non-feature columns if present
feature_cols = [c for c in merged.columns if c not in drop_cols]
print("Number of features:", len(feature_cols))
X = merged[feature_cols].values
y = merged['binary_label'].values
print("X shape:", X.shape, "y shape:", y.shape)

# One-sample .wav visualization for presentation

import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import Audio

# 1) Point to one example .wav file
audio_path = "/content/download.wav"   # <-- change to your file

# 2) Load audio
y, sr = librosa.load(audio_path, sr=None)
print(f"Loaded: {audio_path}")
print(f"Duration: {len(y)/sr:.2f} s, Sample rate: {sr} Hz")

# 3) Play audio (for presentation)
display(Audio(y, rate=sr))

# 4) Create time axis for waveform
t = np.linspace(0, len(y)/sr, num=len(y))

plt.figure(figsize=(15, 10))

# ---- (a) Waveform ----
plt.subplot(3, 1, 1)
librosa.display.waveshow(y, sr=sr)
plt.title("Waveform")
plt.xlabel("Time (s)")
plt.ylabel("Amplitude")

# ---- (b) Spectrogram (log-magnitude STFT) ----
D = librosa.stft(y)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

plt.subplot(3, 1, 2)
librosa.display.specshow(S_db,
                         sr=sr,
                         x_axis="time",
                         y_axis="log",
                         cmap="magma")
plt.colorbar(format="%+2.0f dB", label="dB")
plt.title("Spectrogram (log-frequency)")
plt.xlabel("Time (s)")
plt.ylabel("Frequency (Hz)")

# ---- (c) MFCC heatmap ----
mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
plt.subplot(3, 1, 3)
librosa.display.specshow(mfccs,
                         x_axis="time",
                         cmap="viridis")
plt.colorbar(label="MFCC")
plt.title("MFCCs (13 coefficients)")
plt.xlabel("Time (s)")
plt.ylabel("MFCC index")

plt.tight_layout()
plt.show()

print(X.shape)
print(y.shape)

# If y is a DataFrame, convert to Series
y = y.squeeze()  # or y = y.values.ravel()

from sklearn.model_selection import train_test_split

# Re-assign y to the correct labels from the merged dataframe
y = merged['binary_label'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Train:", X_train.shape, "Test:", X_test.shape)

# Cell 9: quick XGBoost baseline
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score

xgb_base = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)
xgb_base.fit(X_train, y_train)
pred = xgb_base.predict(X_test)
prob = xgb_base.predict_proba(X_test)[:,1]
print(classification_report(y_test, pred))
try:
    print("AUC:", roc_auc_score(y_test, prob))
except Exception as e:
    print("AUC error:", e)

# Cell 10: randomized hyperparameter search
from sklearn.model_selection import RandomizedSearchCV
import numpy as np
from scipy.stats import randint, uniform


param_dist = {
    'n_estimators': [100,200,400,800],
    'max_depth': randint(3,12),
    'learning_rate': uniform(0.01, 0.4),
    'subsample': uniform(0.5, 0.5),
    'colsample_bytree': uniform(0.5, 0.5),
    'reg_alpha': uniform(0, 1.0),
    'reg_lambda': uniform(0, 1.0)
}

xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)

rs = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=param_dist,
    n_iter=40,                # increase for more thorough search
    scoring='roc_auc',
    cv=4,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

rs.fit(X_train, y_train)
print("Best params:", rs.best_params_)
print("Best CV score:", rs.best_score_)

best_xgb = rs.best_estimator_

# Cell 11: evaluation with best model
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, classification_report

y_pred = best_xgb.predict(X_test)
y_prob = best_xgb.predict_proba(X_test)[:,1]

print("Classification report:")
print(classification_report(y_test, y_pred))

# Confusion matrix with custom colors
cm = confusion_matrix(y_test, y_pred, labels=[0,1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["neg","pos"])
fig, ax = plt.subplots(figsize=(5,5))
disp.plot(ax=ax, cmap=plt.cm.Blues)  # Change cmap to your preferred color
plt.title("Confusion Matrix")
plt.show()


# ROC curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr)   # default matplotlib color
plt.plot([0,1],[0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(f"ROC curve (AUC = {roc_auc:.3f})")
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import librosa.display
import librosa # Import librosa if not already
import numpy as np # Import numpy if not already

# Re-load the audio data for MFCC computation
# Using the original audio_path and sr from Cell xITqyXJAIRG9
original_audio_y, original_audio_sr = librosa.load(audio_path, sr=None)

# Compute MFCCs using the re-loaded audio data
mfccs = librosa.feature.mfcc(y=original_audio_y, sr=original_audio_sr, n_mfcc=20)

# Plot MFCC heatmap
plt.figure(figsize=(10,4))
librosa.display.specshow(mfccs, x_axis='time', sr=original_audio_sr, cmap='magma')
plt.colorbar(label='MFCC amplitude')
plt.ylabel('MFCC Coefficient')
plt.title('MFCC of .WAV')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import shap

# TreeExplainer for best XGBoost model
explainer = shap.TreeExplainer(best_xgb)

# Subset if dataset is large
X_shap = X_test if X_test.shape[0] <= 2000 else X_test[np.random.choice(X_test.shape[0], 1000, replace=False)]
shap_vals = explainer.shap_values(X_shap)

# Convert to numpy array if needed
shap_matrix = np.array(shap_vals)

# Plot as MFCC-like heatmap
plt.figure(figsize=(12,6))
plt.imshow(shap_matrix.T, aspect='auto', origin='lower', cmap='magma')  # 'magma', 'viridis', 'coolwarm', etc.
plt.colorbar(label='SHAP value')
plt.ylabel("Features")
plt.yticks(ticks=np.arange(len(feature_cols)), labels=feature_cols)
plt.xlabel("Samples")
plt.title("MFCC-style SHAP Heatmap")
plt.tight_layout()
plt.show()

# Cell 13: save model and merged features+labels
import joblib, os
os.makedirs('/content/models', exist_ok=True)
joblib.dump(best_xgb, '/content/models/xgb_best_coswara.pkl')
print("Saved best_xgb to /content/models/xgb_best_coswara.pkl")

merged.to_csv('/content/merged_features_labels.csv', index=False)
print("Saved merged dataframe to /content/merged_features_labels.csv")

# Cell 14: optional quick comparison
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)
from sklearn.metrics import roc_auc_score
print("RF AUC:", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))
print("XGB AUC:", roc_auc_score(y_test, best_xgb.predict_proba(X_test)[:,1]))